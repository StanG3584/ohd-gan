
%%%%%%%%%%%%%%%%%%%%%%%%%%% Algorithms
\newglossaryentry{gumbel-gan}
{
        name=Gumbel-Softmax GAN,
        description={}
}

\newglossaryentry{arae}
{
        name=ARAE,
        description={Adversarially regularized autoencoders.}
}

\newglossaryentry{t-sne}{
    name=t-SNE,
    description={The t-Distributed Stochastic Neighbor Embedding clustering algorithm is a nonlinear dimensionality reduction technique commonly applied to high-dimensiona data. See \citet{maaten2008tsne}.}
}

\newglossaryentry{mode-collapse}
{
        name=mode collapse,
        description={The training procedure fails to converge, or converges to an undesirable local minima resulting in a lack of variety in the generated samples.}
}

\newglossaryentry{feed-forward}
{
        name=feed-forward network,
        description={Basic Neural Network in its simplest form.}
}

\newglossaryentry{mb-avg}
{
        name=Mini-batch averaging,
        description={Adaptation of mini-batch averaging to cope with mode collapse, see \cite{choi2017generating}}
}

\newglossaryentry{dom-tran}{
    name=domain translation,
    description={Transforming data points from one domain or category to another.}
}

\newglossaryentry{semi-sup}{name=semi-supervised, description={\todo{definition}
}}

\newglossaryentry{re-iden}{name=reidentification attack, description={\todo{definition}
}}

\newglossaryentry{dbio}{name=digital bio-markers, description={\todo{definition}
}}

\newglossaryentry{exploding}{name=exploding gradient,
    description={The gradients accumulate large amounts of error, destabilising or disabling the training procedure.}
}

\newglossaryentry{vanishing}{name=vanishing gradient, description={The gradients become null and the network can no longer be updated.
}}

\newglossaryentry{a-disclosure}{name=Attribute disclosure, description={\todo{definition}}}

\newglossaryentry{mem-inference}{name=Membership inference, description={\todo{definition}}}

\newglossaryentry{repro-rate}{name=Reproduction rate, description={\todo{definition}}}

\newglossaryentry{utility-metric}{name=utility-based metric, description={In a broad sense, any metric that measure the amount of work that can be done with the data}}

\newglossaryentry{iteff}{name=Individual Treatment Effects, description={\todo{definition}
}}
\newglossaryentry{pmed}{name=Personalized Medicine, description={\todo{definition}
}}

\newglossaryentry{}{name=, description={
}}

%% Missingness
\newglossaryentry{mar}{name=Missing at Random, description={Given a dataset with missing entries , the missingness depends only on the observed variables \cite{yoon2018imputation}.
}}

\newglossaryentry{mcar}{name=Missing Completly at Random, description={Given a dataset with missing entries, the missingness is not depedant on any of the variables, thus occurs completly at random \cite{yoon2018imputation}.
}}

%% Self and co-training semi-supervised training
\newglossaryentry{co-training}{name=co-training, description={The self-training and co-training methods use classifiers first trained on the portion of labelled data to predict the labels of unlabelled instances. The newly labelled samples with the highest confidence are added to the labelled set to retrain the classifiers. The process is repeated iteratively.}}

\newglossaryentry{self-training}{name=self-training, description={The self-training and co-training methods use classifiers first trained on the portion of labelled data to predict the labels of unlabelled instances. The newly labelled samples with the highest confidence are added to the labelled set to retrain the classifiers. The process is repeated iteratively.
}}

%% Privacy
\newglossaryentry{mia}{name=Membership Inference Attack, description={Broadly, an MIA attack aims to determine if a particular record was used to train a machine learning model \cite{chen2019ganleaks}. There is no canonical process by which an attack is conducted, nor specification of the data assets initially in possession of the attacker. For a comprehensive taxonomy of MIA against \gls{gan}, refer to the suitably titled publication by \citeauthor{chen2019ganleaks} in which \gls{medgan} was subjected to a number of trials.}}

%% Training techniques
\newglossaryentry{msn}{
 type=\acronymtype,
 name={MSN},
 description={Per feature, a variational Gaussian mixture model is used to estimate the number of modes and fit a Gaussian mixture. A one-hot vector indicating the mode, and a scalar indicating the value within the mode is produced. See \cite{Xu2019-ay}.},
 text={MSN},
 first={Mode-specific normalization (MSN)}
}

\newglossaryentry{tbs}{
    type=\acronymtype,
    name={TbS}, 
    description={To deal with the imbalance of values in categorical featues, during training the data is resampled in a way that all the categories from discrete attributes are sampled evenly, without inducing bias and so as to recover real data distribution. See \cite{Xu2019-ay} for a step-by-step spefication.}
    text={TbS},
    first={Training by sampling (TbS)}  
}

\newglossaryentry{nnaa}{
    type=\acronymtype,
    name={NN-AA}, 
    description={"Compares the distance from one point in a target distribution T, to the nearest point in a source distribution S, to the distance to the next nearest point in the target distribution." See \cite{yale2019ESANN}.}
    text={NN-AA},
    first={Nearest-neighbor Adversarial Accuracy (NN-AA)}
}

\newglossaryentry{pl}{
    type=\acronymtype,
    name={PL}, 
    description={Difference of \gls{NN-AA} on the test set and on the training set. See \cite{yale2019ESANN}.}
    text={PL},
    first={Privacy loss (PL)}
}

\newglossaryentry{dt}{
    type=\acronymtype,
    name={DT}, 
    description={The discriminator is tested on batches of synthetic data produced by other methods to asses the possibility of overfitting, see \cite{yale2019ESANN}.}
    text={DT},
    first={Discriminator testing (DT)}
}

\newglossaryentry{do}{
    type=\acronymtype,
    name={DO}, 
    description={Privacy preservation method. See \cite{yale2019ESANN} based on \cite{Dwork2008, Prasser2017}.}
    text={DO},
    first={Data obfuscation (DO}
}

\newglossaryentry{pate}{
    type=\acronymtype,
    name={PATE}, 
    description={Differntial privacy method: "The approach combines, in a black-box fashion, multiple models trained with disjoint datasets, such as records from different subsets of users. Because they rely directly on sensitive data, these models are not published, but instead used as "teachers" for a "student" model. The student learns to predict an output chosen by noisy voting among all of the teachers, and cannot directly access an individual teacher or the underlying data or parameters. The student's privacy properties can be understood both intuitively (since no single teacher and thus no single dataset dictates the student's training) and formally, in terms of differential privacy." \cite{Papernot2017,Papernot2018}}
    text={PATE},
    first={Private Aggregation of Teacher Ensembles (PATE)}
}

\newglossaryentry{mbd}{
    type=\acronymtype,
    name={MBD}, 
    description={Training technique. See \cite{Salimans2016}}
    text={MBD},
    first={Mini-batch discrimination (MDB)}
}

\newglossaryentry{t-gan}{
    type=\acronymtype,
    name={T-GAN}, 
    description={Training technique to stabilise training. Allows the introduction of real sample information into the process of training the the generator. See \cite{Jolicoeur-Martineau2019, Su2018}}
    text={T-GAN},
    first={Turing \gls{gan}}
}

\newglossaryentry{corrnn}{
    type=\acronymtype,
    name={CorrNN}, 
    description={Learns a common representation of two views, taking into account their correlation. See \cite{Jolicoeur-Martineau2019, Su2018}}
    text={CorrNN},
    first={Correlation \gls{nn}}
}

\newacronym{}{Grouped CorrNN}{Grouped Correlation Neural Network}

% \newglossaryentry{⟨label ⟩}{type=\acronymtype,
% name={⟨abbrv ⟩},
% description={⟨long⟩},
% text={⟨abbrv ⟩},
% first={⟨long⟩ (⟨abbrv ⟩)},
% plural={⟨abbrv ⟩\glspluralsuffix},
% firstplural={⟨long⟩\glspluralsuffix\space (⟨abbrv ⟩\glspluralsuffix)},
% ⟨key-val list⟩}

%% Algorithms
\newacronym{nn}{NN}{Neural Network}
\newacronym{gan}{GAN}{Generative Adversarial Network}
\newacronym{ohd-gan}{OHD-GAN}{\glspl{gan} for Observation Health Data}
\newacronym{ffn}{FFN}{\gls{feed-forward} Network}
\newacronym{ae}{AE}{Autoencoder}
\newacronym{rnn}{RNN}{Reccurent \gls{nn}}
\newacronym{lstm}{LSTM}{Long Short-term Memory}
\newacronym{cgan}{CGAN}{Conditional \gls{gan}}
\newacronym{crmb}{CRMB}{Conditional Restricted Boltzamann Machine}
\newacronym{cnn}{CNN}{Convolutional \gls{nn}}
\newacronym{wgan}{WGAN}{Wassertein \gls{gan}}
\newacronym{beta-vae}{\ensuremath{\beta}-VAE}{\ensuremath{\beta} variational auto-encoder}
\newacronym{lr}{LR}{Logistic-regression}
\newacronym{cycle-gan}{Cycle-GAN}{Cycle-consistent \gls{gan}}
\newacronym{adtep}{ADTEP}{Adversarial Deep Treatment Effect Prediction}
\newacronym{cae}{CAE}{Convolutional \gls{AE}}

\newacronym[type=oalgo]{medgan}{medGAN}{medGAN}
\newacronym[type=oalgo]{ssl-gan}{SSL-GAN}{Semi-supervised Learning with a learned ehrGAN}
\newacronym[type=oalgo]{wgantpp}{WGANTPP}{\gls{wgan} for Temporal Point-processes}
\newacronym[type=oalgo]{radialgan}{RadialGAN}{RadialGAN}
\newacronym[type=oalgo]{mc-arae}{MC-ARAE}{Multi-categorical gls{arae}}
\newacronym[type=oalgo]{ctgan}{CTGAN}{Conditional Tabular \Gls{gan}}
\newacronym[type=oalgo]{heterogan}{HGAN}{Heterogeneous GAN}
\newacronym[type=oalgo]{emr-wgan}{EMR-WGAN}{EMR Wassertein GAN}
\newacronym[type=oalgo]{corgan}{corGAN}{corGAN}
\newacronym[type=oalgo]{1d-cae}{1D-CAE}{1-dimensional Convolutional \gls{ae}}
\newacronym[type=oalgo]{ehrgan}{ehrGAN}{Electronic Health Record GAN}
\newacronym[type=oalgo]{rgan}{RGAN}{Recurrent \gls{gan}}
\newacronym[type=oalgo]{rcgan}{RC-GAN}{Recurrent Convolutional \gls{gan}}
\newacronym[type=oalgo]{ganite}{GANITE}{Generative Adversarial Nets for inference of Individualized Treatment Effects}
\newacronym[type=oalgo]{cwr-gan}{CWR-GAN}{Cycle Wasserstein Regression \gls{gan}}
\newacronym[type=oalgo]{gain}{GAIN}{Generative Adversarial Imputation Network}
\newacronym[type=oalgo]{mc-medgan}{MC-medGAN}{Multi-categorical \gls{medgan}}
\newacronym[type=oalgo]{mc-gumbelgan}{MC-GumbelGAN}{Multi-categorical Gumbel-softmax \gls{gan}}
\newacronym[type=oalgo]{mc-wgan-gp}{MC-WGAN-GP}{Multi-categorical \gls{wgan} with Gradient Penality}
\newacronym[type=oalgo]{medbgan}{MedBGAN}{Boundry-seeking \gls{medgan}}
\newacronym[type=oalgo]{healthgan}{HealthGAN}{}
\newacronym[type=oalgo]{medwgan}{MedWGAN}{Wassertein \gls{medgan}}
\newacronym[type=oalgo]{sc-gan}{SC-GAN}{Sequentially Coupled \gls{gan}}
\newacronym[type=oalgo]{rmb}{RMB}{Restricted Boltzmann Machine}
\newacronym[type=oalgo]{anomigan}{AnomiGAN}{GANs for anonymizing private medical data}
\newacronym[type=oalgo]{wgan-gp}{WGAN-GP}{\gls{wgan} with Gradient Penality}
\newacronym[type=oalgo]{dp-auto-gan}{DP-auto-GAN}{\gls{DP}-auto-\gls{gan}}
\newacronym[type=oalgo]{ads-gan}{ADS-GAN}{Anonymization through data synthesis using \gls{gan}}
\newacronym[type=oalgo]{gcgan}{GcGAN}{\gls{corrnn} and \gls{t-wgan}}
\newacronym[type=oalgo]{t-wgan}{T-wGAN}{Wassertein \gls{t-gan}}
\newacronym[type=oalgo]{conan}{CONAN}{\textit{Co}plementary patter\textbf{n A}augmentatio\textbf{n } }

%\newacronym[type=oalgo]{}{}{}
%\newacronym{}{}{}

%% Terms
\newacronym{sd}{SD}{Synthetic Data}
\newacronym{ohd}{OHD}{Observational Health Data}
\newacronym{ehr}{EHR}{Electronic Health Record}
\newacronym{icu}{ICU}{Intensive Care Unit}
\newacronym{pmf}{PMF}{Probability Mass Function}


%% Fields
\newacronym[seealso=iteff]{ite}{ITE}{Individual Treatment Effects}
\newacronym[seealso=iteff]{dle}{DLE}{Drug Laboratory Effects}
\newacronym[seealso=pmed]{pm}{PM}{Personalized Medicine}
\newacronym{iot}{IoT}{Internet of Things}

%% Techniques
\newacronym{mba}{MbA}{\gls{mb-avg}}
\newacronym{bn}{BN}{batch-normalization}
\newacronym{sc}{SC}{shortcut connections}
\newacronym{cbt}{CBT}{Cluster-based training}
\newacronym{vcd}{VCD}{Variational contrastive divergence}
\newacronym{ln}{LN}{Layer normalisation}
\newacronym{ssl}{SSL}{Semi-supervised Learning}
\newacronym{sn}{SN}{Spectral Normalization}


%% Privacy
\newacronym{dp}{DP}{Differential privacy}
\newacronym{dp-sgd}{DP-SGD}{Differential private stochastic gradient descent}
\newacronym{ad}{AD}{Attribute Disclosure}
\newacronym[seealso=mia]{pd}{PD}{Presence Disclosure}
\newacronym{rr}{RR}{Reproduction rate}
\newacronym[seealso=mia]{mi}{MI}{Membership Inference}

\newacronym{anm}{ANM}{Additive noise model}


%% Evaluation qualitative
\newacronym{ved}{VED}{Visual Expert Discrimination}

%% Evaluation statistics
\newacronym{dwpro}{DWS}{Dimension-wise Statistics}
\newacronym{dwpre}{DWP}{Dimension-wise Prediction}

%% Evaluation quantitative
\newacronym{fd}{FD}{Feature distributions}
\newacronym{qq}{QQ}{Quantile-quantile plot}
\newacronym{lsr}{LSR}{Latent space representation}
\newacronym{rdp}{RDP}{Renyi Differential Privacy}
\newacronym{pcam}{PCAM}{\gls{pca} Marginal}
\newacronym{pca}{PCA}{Principal Component Analysis}
\newacronym{pcawdd}{PCA-DWD}{\gls{pca} Distributinal Wassertein Distance}

%% Metrics
\newacronym{fop}{F-OP}{First-order proximity}
\newacronym{cc}{CC}{Correlation coefficient}
\newacronym{md-cc}{MD-CC}{\todo{Redundant?}}
\newacronym{mmd}{MMD}{Maximum Mean Discrepency}
\newacronym{rbf}{RBF}{Radial Basis Function}
\newacronym{mse}{MSE}{Mean Squared Error}
\newacronym{auroc}{AUROC}{Area under ROC curve}
\newacronym{auprc}{AUPRC}{Area under the precision-recall curve}
\newacronym{kld}{KLD}{Kullback-Leibler divergence}

%% Evaluation augmentation
\newacronym{tstr}{TSTR}{Train on synthetic, test on real}
\newacronym{trts}{TRTTS}{Train on real, test on synthetic}
\newacronym{pta}{PTA}{Prediction task accuracy}
\newacronym{ssa}{SSA}{Semi-supervised augmentation}




