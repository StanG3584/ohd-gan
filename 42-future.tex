\section{Directions for future research}
\subsection{Building a patient model}
The ultimate goal for generative models of OHD must be to develop an algorithm capable of learning an all encompassing patient model. It would then be possible to generate full EHR records on demand, integrating genetic, lifestyle, environmental, biochemical, imaging, clinical information into high-resolution patient profiles \cite{Capobianco2020}. This is in fact the intention of the patient simulator Synthea. However, Synhea will eventually face a problem with scalability and the capacity of semi-independent state-transition models to coordinate in capturing long-range correlations.\par

Once basic models of health data, as described in Section \ref{sec:basic}, have been developed and validated, these can be progressively combined in a modular fashion to obtain increasingly complex patient simulators. Furthermore, having designed the architecture of these basic models on the underlying data in a way that is comprehensible, as described in \ref{sec:archi}, will facilitate the composition of more complex models. Inputs, outputs and parts of these models can be conditionally attached to others such that the generative process occurs in a way that reflects the real generative process.

\subsection{Evaluating complex patient models}
Once more complex models are developed, the problem is again finding meaningful evaluation metrics of data realism. Capobiano et al. insist on the necessity for data performance metrics encompassing diagnostic accuracy, early intervention, targeted treatment and drug efficacy \cite{Capobianco2020}. In their publication exploring the validation of the data produced by Synthea, Chen et al. provide an interesting idea to achieve this \cite{Chen_2019}. Noting that the quality of care is the prime objective of a functional healthcare system, they suggest using \hyperlink{CQM}{Clinical quality measures (CQM)} to evaluate the synthetic data. These measures "are evidence-based metrics to quantify the processes and outcomes of healthcare", such as "the level of effectiveness, safety and timeliness of the services that a healthcare provider or organization offers."(Chen 2019). High-level indicators such as \hypertarget{CQM}{CQMs} domain specific measures of quality, specifically designed for higher level or multimodal representations of healthcare data. The constraints introduced in HGAN should be leverage to evaluate the realism of the synthetic data, rather than bias the generator training. Composing a comprehensive set of such constraints could possibly serve as a standardized benchmark.
At the individual level, Walsh et al. employ domain specific indicators of disease progression and worsening and compare agreement of the simulated patient trajectories with the factual timelines \cite{walsh2020generating}.\par
In addition to \hypertarget{CQM}{CQMs}, we propose the use of the Care maps used by the Synthea model to simulate patient trajectories as evaluation metrics \cite{Walonoski_2017}. Care maps are transition graphs developed from clinician input and Clinical Practice Guidelines, of which the transition probabilities are gathered from health incidence statistics. While these allow the Synthea algorithm to simulate patient profile with realistic structure, they also prevent it from reproducing real-world variability. Conversely, while \glspl{gan} have the ability to reproduce the quirks of real data, they also lack the constraints preventing nonsensical outputs. As such, Care maps provide an ideal metric to check if the synthetic data conforms to medical processes.\par 
In fact, has been used before in a competition where participants were given synthetic data from finite state transition machines with know probabilities and tasked to build and learn models that would reproduce those of the original, unseen models. The participants according to the Perplexity metric. Commonly used in NLP, quantifies how well a probability distribution or probability model predicts a sample \cite{Verwer_2013}. We postulate that the Synthea models built with real-world probabilities would provide a unique and robust way to evaluate synthetic data according to the metric proposed above, among other means to utilize the state-transition in Syntea and their modularity.

\subsubsection{Opportunities and application to current events}
Synthetic and external controls in clinical trials are becoming increasingly popular \cite{Thorlund2020}. Synthetic controls refer to cohorts that have been composed from real observational cohorts or EHR using statistical methodologies. While the individuals included in the cohorts are usually left unchanged, microsimulations of disease progression at the patient level are used to explore long-term outcomes and help in the estimation of treatment effects (Thorlund 2020, Etzioni 2002). Synthetic data generated by \glspl{gan} could be transformative for the problem of finding control cohorts.\par
With the COVID-19 pandemic scientists have become increasingly aware of and vocal about the need for data sharing between political borders \cite{Cosgriff_2020,Becker_2020,McLennan_2020}. An obvious application is generating additional amounts of data in the early stages of the pandemic, potentially creating opportunities earlier. Synthetic is data not only an opportunity to facilitate the exchange of data, but also adjust the biases of samples obtained from different localities. Factors such as local hospital practices, different patient populations and equipment introduce feature and distribution mismatches \cite{Ghassemi2020}. These disparities can be mitigated by translation of \gls{gan} algorithms, such as CycleGAN proposed by Yoon et al.

