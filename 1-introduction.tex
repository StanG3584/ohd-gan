\section{Introduction}
\subsection{Background}
Most \gls{ohd} is collected as \glspl{ehr} at various points of care in a patientâ€™s trajectory, primarily to support and enable healthcare professionals \cite{Cowie_2016}. The patient profiles found in \glspl{ehr} are diverse and longitudinal, composed of demographics variables, recordings of diagnoses, conditions, procedures, prescriptions, measurements and lab test results, administrative information, and increasingly omics \cite{Ohdsi2020-vf}.\par
Having served its primary purpose, this wealth of detailed information can further benefit patient well-being by sustaining medical research and development. This could mean improving the development life-cycle of health informatics (HI), the predictive accuracy of machine learning (ML) algorithms or enabling discoveries in research concerning clinical decisions, triage decisions, inter-institution collaborations and HI automation \cite{Rudin_2020}. Big health data is the underpinning of two main objectives of precision medicine: individualization of patient interventions and the inference of biological systems from high level analysis \cite{Capobianco2020}. However, the potential for secondary usage of \gls{ohd} continues to be hampered by the fiercely private nature of patient-related data, and the growing popular concern towards its disclosure.\par
Anonymization techniques are generally employed to hinder misuse of sensitive data. Most often, through a costly and data specific cleansing process, privacy is enhanced at the detriment of data utility. Moreover, these techniques are fallible, and never fully prevent re-identification.To address this problem, alternative methods for sharing sensitive data have been proposed, such as privacy-preserving distributed analysis. Although promising, these approaches come with their own limitations.\par
Consequently, access to \gls{ohd} is restricted to professionals with the appropriate academic credentials and financial resources, preventing its use for the rest of the health data related occupations. For example, software developers often do not have access to the data that will be processed by the health informatics solutions they are developing.
\subsection{Synthetic data}
An alternative to traditional privacy-preserving methods is to produce fully synthetic data,with methods to build these models including knowledge-driven and data-driven modelling \cite{Kim_2017}. Knowledge-driven modelling involves a complex theory-based process to define a simulation process representing the causal relationships of a system. The Synthea \cite{Walonoski_2017} synthetic patient generator is one such simulation model, in which predefined states, transitions, and conditional logic produce patient trajectories. The parameters of the Synthea model are taken from aggregate population-level statistics of disease progression and medical knowledge. A knowledge-based approach such as Synthea depends on prior knowledge of the system, and most importantly how much we can understand about it \cite{Kim_2017}. When modelling complex systems, simplifications and assumptions are inevitable, leading to inaccuracies. For example, relying on population-level statistics does not produce models capable of reproducing heterogeneous health outcomes \cite{Chen_2019}.\par
In data-driven modelling techniques, a representation of the data is inferred from a sample distribution. There exists numerous statistical modelling approaches to produce synthetic data, but the modelling processes are based on intrinsic assumptions about the data, the representational power is bound to the correlations that are intelligible to the modeler or are prone to obscure inaccuracies. Synthetic data generated by these models tends to possess low utility \cite{Rankin2020}. In the ML field, generative models learn to represent an estimate of the multi-modal distribution, from which synthetic samples can be drawn \cite{goodfellow2016nips}. Generative Adversarial Networks (GAN) \cite{NIPS2014_5423} have recently emerged as a groundbreaking approach to efficiently learn generative models that produce realistic Synthetic Data (SD) using \gls{nn}. GAN algorithms have rapidly found a wide range of applications, such as data augmentation in medical imaging \cite{Kadurin_2017}.\par
The potential impacts of GAN to healthcare and science are considerable, some of which have been realized in fields such as medical imaging \cite{Yi_2019}. However, the application of GAN to \gls{ohd} seems to have been lagging \cite{Xiao_2018}. Certain characteristics of \gls{ohd} could serve to explain the relatively slow progress. Primarily, algorithms developed for images and text in other fields were easily re-purposed for medical equivalents. However, \gls{ohd} presents unique complexity in terms of multi-modality, heterogeneity and fragmentation \cite{Xiao_2018}. In addition to this, evaluating the realism of synthetic \gls{ohd} is intuitively complex, a problem that still burdens GAN in general. Nonetheless, interesting GAN solutions to the challenges posed by \gls{ohd} have been developed \cite{esteban2017real,Che_2017,choi2017generating,yahi2017generative}.